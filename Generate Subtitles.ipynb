{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Subtitles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this project show steps to generate subtitles for your video file.\n",
    "\n",
    "Note:\n",
    "    1. Python libraries mostly work on wav audio formats, so I converted the video to audio (.wav extension) in the code.\n",
    "    2. Google Cloud APIs work properly on locally stored files only if the audio files are < 1 minute. \n",
    "    (Otherwise you need to store the file on Cloud Bucket)\n",
    "    So, while converting the audios here, I also trimmed the audio to 50 second duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import io\n",
    "from google.cloud import speech_v1\n",
    "from google.cloud.speech_v1 import enums\n",
    "from google.cloud.speech_v1 import types\n",
    "from pydub.utils import mediainfo\n",
    "import datetime\n",
    "import subprocess\n",
    "import srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the video you want subtitles for.\n",
    "\n",
    "path = \"C:/DummyPath/\"\n",
    "video =  path + \"C4W1L01 Computer Vision.mp4\" \n",
    "#This should be set to the path of your service account credentials JSON file.\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'Cloud_AIML.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud_AIML.json\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the sample rate, bit rate and no. of channels from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_info(video_filepath):\n",
    "    \"\"\" this function returns number of channels, bit rate, and sample rate of the video\"\"\"\n",
    "\n",
    "    video_data = mediainfo(video_filepath)\n",
    "    channels = video_data[\"channels\"]\n",
    "    bit_rate = video_data[\"bit_rate\"]\n",
    "    sample_rate = video_data[\"sample_rate\"]\n",
    "\n",
    "    return channels, bit_rate, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels, bit_rate, sample_rate = video_info(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44100'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert video to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[input_name, input_type] = os.path.splitext(video)\n",
    "output_name = input_name.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path = '\"' + path + \"audio/\" + output_name + \".wav\" + '\"'\n",
    "video_path = '\"' + video + '\"'\n",
    "command = f\"ffmpeg -i { video_path } -b:a {bit_rate} -ac {channels} -ar {sample_rate} -t 00:00:50.0 -vn { audio_path }\"\n",
    "subprocess.call(command, shell=True)\n",
    "\n",
    "# Output '0' means success and '1' means failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to where audio is stored.\n",
    "\n",
    "audio = path + \"audio/\" + output_name + \".wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing the audio file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_running_recognize(local_file_path, sample_rate, channels):\n",
    "   \n",
    "    client = speech_v1.SpeechClient()\n",
    "\n",
    "\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "    config = {\n",
    "        \"language_code\": \"en-US\",\n",
    "        \"sample_rate_hertz\": int(sample_rate),\n",
    "        \"encoding\": enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        \"audio_channel_count\": int(channels),\n",
    "        \"enable_word_time_offsets\": True,   #provides timing information\n",
    "        \"model\": \"video\",\n",
    "        \"enable_automatic_punctuation\":True\n",
    "    }\n",
    "    with io.open(local_file_path, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n"
     ]
    }
   ],
   "source": [
    "response=long_running_recognize(audio, sample_rate, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtitle_generation(speech_to_text_response, bin_size=4):\n",
    "    \"\"\"We define a bin of time period to display the words in sync with audio. \n",
    "    Here, bin_size = 3 means each bin is of 3 secs. \n",
    "    All the words in the interval of 3 secs in result will be grouped togather.\"\"\"\n",
    "    transcriptions = []\n",
    "    index = 0\n",
    " \n",
    "    for result in response.results:\n",
    "        try:\n",
    "            if result.alternatives[0].words[0].start_time.seconds:\n",
    "                # bin start -> for first word of result\n",
    "                start_sec = result.alternatives[0].words[0].start_time.seconds \n",
    "                start_microsec = result.alternatives[0].words[0].start_time.nanos * 0.001\n",
    "            else:\n",
    "                # bin start -> For First word of response\n",
    "                start_sec = 0\n",
    "                start_microsec = 0 \n",
    "            end_sec = start_sec + bin_size # bin end sec\n",
    "            \n",
    "            # for last word of result\n",
    "            last_word_end_sec = result.alternatives[0].words[-1].end_time.seconds\n",
    "            last_word_end_microsec = result.alternatives[0].words[-1].end_time.nanos * 0.001\n",
    "            \n",
    "            # bin transcript\n",
    "            transcript = result.alternatives[0].words[0].word\n",
    "            \n",
    "            index += 1 # subtitle index\n",
    "\n",
    "            for i in range(len(result.alternatives[0].words) - 1):\n",
    "                try:\n",
    "                    word = result.alternatives[0].words[i + 1].word\n",
    "                    word_start_sec = result.alternatives[0].words[i + 1].start_time.seconds\n",
    "                    word_start_microsec = result.alternatives[0].words[i + 1].start_time.nanos * 0.001 # 0.001 to convert nana -> micro\n",
    "                    word_end_sec = result.alternatives[0].words[i + 1].end_time.seconds\n",
    "                    word_end_microsec = result.alternatives[0].words[i + 1].end_time.nanos * 0.001\n",
    "\n",
    "                    if word_end_sec < end_sec:\n",
    "                        transcript = transcript + \" \" + word\n",
    "                    else:\n",
    "                        previous_word_end_sec = result.alternatives[0].words[i].end_time.seconds\n",
    "                        previous_word_end_microsec = result.alternatives[0].words[i].end_time.nanos * 0.001\n",
    "                        \n",
    "                        # append bin transcript\n",
    "                        transcriptions.append(srt.Subtitle(index, datetime.timedelta(0, start_sec, start_microsec), datetime.timedelta(0, previous_word_end_sec, previous_word_end_microsec), transcript))\n",
    "                        \n",
    "                        # reset bin parameters\n",
    "                        start_sec = word_start_sec\n",
    "                        start_microsec = word_start_microsec\n",
    "                        end_sec = start_sec + bin_size\n",
    "                        transcript = result.alternatives[0].words[i + 1].word\n",
    "                        \n",
    "                        index += 1\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            # append transcript of last transcript in bin\n",
    "            transcriptions.append(srt.Subtitle(index, datetime.timedelta(0, start_sec, start_microsec), datetime.timedelta(0, last_word_end_sec, last_word_end_microsec), transcript))\n",
    "            index += 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    # turn transcription list into subtitles\n",
    "    subtitles = srt.compose(transcriptions)\n",
    "    return subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles= subtitle_generation(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store subtitles in a new .srt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"subtitles.srt\", \"w+\") as f:\n",
    "    f.write(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
